# -*- coding: utf-8 -*-
# @Time    : 2018/12/18 下午5:00
# @Author  : scl
# @Email   : 1163820757@qq.com
# @File    : 决策树构建过程理解案例.py
# @Software: PyCharm

import numpy as  np

'''
 计算信息熵
 :param t 一个概率组合
 :return 信息熵的值
'''
def entropy(t):
    return np.sum([-i * np.log2(i) for i in t])


'''
 计算gini系数
'''
def gini(t):
    return 1 - np.sum(np.array(t)**2)




h = entropy([0.7,0.3])
print('原始数据的信息熵%.3f'%h)

# 1 以房产作为划分属性考虑
p11 = 0.4 #有房产的概率
h11 = entropy([1.0]) #有房信息熵

p12 = 0.6 #无房产的概率
h12 = entropy([0.5,0.5]) # 无房的信息熵

# 合并信息熵 得到以房产作为特征划分的条件熵
h1 = p11 * h11 + p12 * h12

print("以房产作为条件的条件熵%.3f"%h1)
print("以房产作为划分特征时候的信息增益:%.3f" % (h - h1))


# 2 以婚姻情况作为划分属性考虑
p21 = 0.3 # 离婚
h21 = entropy([1.0/3.0,2.0/3.0])


p22 = 0.4 #单身
h22 = entropy([0.5, 0.5])

p23 = 0.3 #已婚
h23 = entropy([1.0])

# 合并信息熵 得到以婚姻作为特征划分的条件熵
h2 = p21*h21 + p22*h22 + p23*h23
print("以婚姻情况作为划分特征时候的条件熵:%.3f" % h2)
print("以婚姻情况作为划分特征时候的信息增益:%.3f" % (h - h2))


# 以年收入80作为分割点 划分属性考虑
p31 = 0.2 # 小于80
h31 = entropy([1.0])

p32 = 0.8 #大于80
h32 = entropy([5.0/8.0,3.0/8.0])

h3 = p31*h31 + p32*h32
print("以年收入80作为划分特征时候的条件熵:%.3f" % h3)
print("以年收入80作为划分特征时候的信息增益:%.3f" % (h - h3))



#  以年收入97.5作为分割点的划分属性考虑
# 年收入小于97.5，样本数目：5(2,3)
p41 = 0.5
h41 = entropy([2.0 / 5, 3.0 / 5])
# 年收入大于等于97.5，样本数目：5(5,0)
p42 = 0.5
h42 = entropy([1.0])
# 合并信息熵，得到以年收入97.5作为划分特征时候的条件熵
h4 = p41 * h41 + p42 * h42
print("以年收入97.5作为划分特征时候的条件熵:%.3f" % h4)
print("以年收入97.5作为划分特征时候的信息增益:%.3f" % (h - h4))


'''
原始数据的信息熵  0.881
以房产作为条件的条件熵  0.600
以房产作为划分特征时候的信息增益: 0.281

以婚姻情况作为划分特征时候的条件熵:   0.675
以婚姻情况作为划分特征时候的信息增益: 0.206

以年收入80作为划分特征时候的条件熵:      0.764
以年收入80作为划分特征时候的信息增益:    0.118

以年收入97.5作为划分特征时候的条件熵:    0.485
以年收入97.5作为划分特征时候的信息增益:  0.396

条件熵越小 说明系统越纯 越有序

年收入-->房产-->婚姻
'''






